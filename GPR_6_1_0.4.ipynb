{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Features\n",
    "## Kernel Function 1: RBF + White\n",
    "## Test Size = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF,DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.gaussian_process.kernels import RationalQuadratic\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "# Read and Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data:\n",
      "Mean: [ 57.57512229  80.21663173 137.79175402  25.98588518   0.15063681\n",
      "   3.06218929]\n",
      "Standard Deviation: [24.43648156 37.78841425 61.82343348  8.36100388  0.07366021  2.40608908]\n",
      "\n",
      "Output Data:\n",
      "Mean: [-40.35911008]\n",
      "Standard Deviation: [42.23861824]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_excel (r'training_fixed.xlsx')\n",
    "\n",
    "name=['Z','N','A','A^2/3','(N-Z)/A','PF']\n",
    "\n",
    "x_train = pd.DataFrame(train_data,  columns=name)  \n",
    "y_train = pd.DataFrame(train_data, columns= ['MeV'])\n",
    "\n",
    "test_size = 0.40  \n",
    "random_state = 100 \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=test_size, random_state=random_state)\n",
    "\n",
    "train_len=len(x_train)\n",
    "test_len=len(x_test)\n",
    "\n",
    "#test_data= pd.read_excel (r'test_fixed.xls')\n",
    "#x_test = pd.DataFrame(test_data,  columns=name)  \n",
    "#y_test = pd.DataFrame(test_data, columns= ['MeV'])\n",
    "\n",
    "#test_len=len(x_test)\n",
    "\n",
    "extra_data= pd.read_excel (r'NEW_EXP_DATA_FOR_EXTRAPOLATION.xlsx')\n",
    "x_extra = pd.DataFrame(extra_data,  columns=name)  \n",
    "y_extra = pd.DataFrame(extra_data, columns= ['MeV'])\n",
    "\n",
    "inp=np.concatenate((x_train,x_test,x_extra),axis=0)\n",
    "out=np.concatenate((y_train,y_test,y_extra),axis=0)\n",
    "train_test_len=train_len+test_len\n",
    "##################################\n",
    "## scale\n",
    "##################################\n",
    "#sc_X= StandardScaler()\n",
    "#inp = sc_X.fit_transform(inp)\n",
    "#sc_Y = StandardScaler()\n",
    "#out=sc_Y.fit_transform(out)\n",
    "\n",
    "#x_train=inp[0:train_len]\n",
    "#x_test=inp[train_len:train_test_len]\n",
    "#x_extra=inp[train_test_len::]\n",
    "#y_train=out[0:train_len]\n",
    "#y_test=out[train_len:train_test_len]\n",
    "#y_extra=out[train_test_len::]\n",
    "# Splitting the data\n",
    "\n",
    "x_train = inp[0:train_len]\n",
    "x_test = inp[train_len:train_test_len]\n",
    "x_extra = inp[train_test_len::]\n",
    "y_train = out[0:train_len]\n",
    "y_test = out[train_len:train_test_len]\n",
    "y_extra = out[train_test_len::]\n",
    "\n",
    "##################################\n",
    "## scale\n",
    "##################################\n",
    "# Initialize the StandardScaler for input data\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "sc_X.fit(x_train)\n",
    "\n",
    "# Transform the training and testing data using the fitted scaler\n",
    "x_train = sc_X.transform(x_train)\n",
    "x_test = sc_X.transform(x_test)\n",
    "x_extra = sc_X.transform(x_extra)\n",
    "\n",
    "# Initialize the StandardScaler for output data\n",
    "sc_Y = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data\n",
    "sc_Y.fit(y_train)\n",
    "\n",
    "# Transform the training and testing data using the fitted scaler\n",
    "y_train = sc_Y.transform(y_train)\n",
    "y_test = sc_Y.transform(y_test)\n",
    "y_extra = sc_Y.transform(y_extra)\n",
    "\n",
    "# For input data\n",
    "print(\"Input Data:\")\n",
    "print(\"Mean:\", sc_X.mean_)\n",
    "print(\"Standard Deviation:\", sc_X.scale_)\n",
    "\n",
    "# For output data\n",
    "print(\"\\nOutput Data:\")\n",
    "print(\"Mean:\", sc_Y.mean_)\n",
    "print(\"Standard Deviation:\", sc_Y.scale_)\n",
    "################################\n",
    "name+=['original','prediction']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982914802470673\n",
      "1.7459013656731388 2.0322123034952306 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 1 [(1e-2, 1e3),(1e-5, 1e1),1e-1 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848233449978\n",
      "0.8606491919741821 1.0761631354149876 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 2 [(1e-2, 1e3),(1e-5, 1e1),1e-5] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994372005635561\n",
      "1.0020433945381575 1.1667630351448415 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 3 [(1e-2, 1e3),(1e-5, 1e1),1e-3] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ######## \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982917006726129\n",
      "1.7457887378636054 2.032074366659531 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 4 [(1e-2, 1e3),(1e-10, 1e1),1e-1 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848260627015\n",
      "0.8606463751089554 1.0761614056581073 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 5 [(1e-2, 1e3),(1e-10, 1e1),1e-5 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994391649462493\n",
      "1.0002931108751927 1.1657063141777007 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 6 [(1e-2, 1e3),(1e-10, 1e1),1e-3 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982914802470673\n",
      "1.7459013656731388 2.0322123034952306 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 7 [(1e-2, 1e3),(1e-5, 1e5),1e-1  ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848233449978\n",
      "0.8606491919741821 1.0761631354149876 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 8 [(1e-2, 1e3),(1e-5, 1e5),1e-5  ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994372005635561\n",
      "1.0020433945381575 1.1667630351448415 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 9 [(1e-2, 1e3),(1e-5, 1e5),1e-3  ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-2, 1e3)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982914785748732\n",
      "1.7459022200633285 2.0322132635613515 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 10 [(1e-5, 1e5),(1e-5, 1e1),1e-1 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848258074935\n",
      "0.8606466396292244 1.07616156737971 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 11 [(1e-5, 1e5),(1e-5, 1e1),1e-5 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994372005520024\n",
      "1.0020434048236355 1.1667631572539887 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 12 [(1e-5, 1e5),(1e-5, 1e1),1e-3 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982920340275563\n",
      "1.7456183942679642 2.0318346112340997 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 13 [(1e-5, 1e5),(1e-10, 1e1),1e-1] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848233862784\n",
      "0.8606491491874007 1.0761631145677297 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 14 [(1e-5, 1e5),(1e-10, 1e1),1e-5] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994391022199015\n",
      "1.000349047980854 1.1657332359528074 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 15 [(1e-5, 1e5),(1e-10, 1e1),1e-3] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982914785748732\n",
      "1.7459022200633285 2.0322132635613515 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 16 [(1e-5, 1e5),(1e-5, 1e5),1e-1 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848258074935\n",
      "0.8606466396292244 1.07616156737971 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 17 [(1e-5, 1e5),(1e-5, 1e5),1e-5 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994372005520024\n",
      "1.0020434048236355 1.1667631572539887 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 18 [(1e-5, 1e5),(1e-5, 1e5),1e-3 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-5, 1e5)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982914786633477\n",
      "1.7459021748582682 2.0322132281476866 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 19 [(1e-6, 1e6),(1e-5, 1e1),1e-1] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848229768217\n",
      "0.8606495735832295 1.0761634021429494 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 20 [(1e-6, 1e6),(1e-5, 1e1),1e-5] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994372003984768\n",
      "1.0020435414969153 1.1667631623700563 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 21 [(1e-6, 1e6),(1e-5, 1e1),1e-3] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.998291518495608\n",
      "1.7458818228632995 2.0321866175630956 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 22 [(1e-6, 1e6),(1e-10, 1e1),1e-1 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848251044759\n",
      "0.8606473682986809 1.076162013581682 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 23 [(1e-6, 1e6),(1e-10, 1e1),1e-5 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994391548457561\n",
      "1.0003021183438816 1.1657122068530081 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 24 [(1e-6, 1e6),(1e-10, 1e1),1e-3 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9982914786633477\n",
      "1.7459021748582682 2.0322132281476866 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 25 [(1e-6, 1e6), (1e-5, 1e5),1e-1  ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-1] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9995848229768217\n",
      "0.8606495735832295 1.0761634021429494 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 26 [(1e-6, 1e6), (1e-5, 1e5),1e-5  ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-5] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Charlene/anaconda3/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.9994372003984768\n",
      "1.0020435414969153 1.1667631623700563 nan\n"
     ]
    }
   ],
   "source": [
    "###################### Group 27 [(1e-6, 1e6), (1e-5, 1e5),1e-3 ] ######################  \n",
    "os.chdir(cwd)\n",
    "analyze_name=\"GP_Regression\"\n",
    "if not (os.path.exists(\"./\"+str(analyze_name))):\n",
    "    os.makedirs(\"./\"+str(analyze_name));\n",
    "os.chdir(\"./\"+str(analyze_name));\n",
    "wfile=open(\"results_\"+str(analyze_name)+\"_selected.txt\",\"a\")\n",
    "Scale=[1.0] \n",
    "Alpha=[1e-3] \n",
    "Normalize=[False] \n",
    "\n",
    "# K-fold cross-validation\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for s in Scale:\n",
    "    for a in Alpha:\n",
    "        for n in Normalize:\n",
    "            wfile.write(analyze_name+\"\\n\")\n",
    "            wfile.write(\"Scale : {} Alpha: {} Normalize: {} \\n\".format(str(s),str(a),str(n)))\n",
    "            wfile.write(\"----------------------------------\\n\")\n",
    "            ###############################\n",
    "            ## Model\n",
    "            ################################\n",
    "            #kernel = 1.0 * Matern(length_scale=1.0, nu=2.0,length_scale_bounds=(1e-10, 1e6))+\\\n",
    "            #WhiteKernel(noise_level=1, noise_level_bounds=(1e-20, 1e4))\n",
    "            \n",
    "            kernel = 1.0 * RBF(length_scale=s, length_scale_bounds=(1e-6, 1e6)) +\\\n",
    "            WhiteKernel(noise_level=1, noise_level_bounds=(1e-5, 1e5))\n",
    "            gpr = GaussianProcessRegressor(kernel=kernel,alpha=a,normalize_y=n).fit(x_train, y_train)\n",
    "\n",
    "        \n",
    "            ######## EY: The score is printed  ########  31/10/2023 \n",
    "            score = gpr.score(x_train, y_train)\n",
    "             # Print the score\n",
    "            print(\"R^2 Score:\", score)\n",
    "            ###########################################  \n",
    "\n",
    "            # Cross-validation\n",
    "            #cv_scores = cross_val_score(gpr, x_train, y_train.flatten(), cv=kf, scoring='neg_mean_squared_error')\n",
    "            #mean_cv_score = np.mean(cv_scores)\n",
    "            #wfile.write(f'Mean Cross-Validation Score: {mean_cv_score}\\n')\n",
    "\n",
    "            # Fit the GPR model on the entire training set\n",
    "            #gpr.fit(x_train, y_train.flatten())\n",
    "            \n",
    "            \n",
    "            pred_train=gpr.predict(x_train)  #EY: Train data added\n",
    "            pred_train=pred_train.reshape(-1,1)  \n",
    "                \n",
    "            pred=gpr.predict(x_test)\n",
    "            pred=pred.reshape(-1,1)\n",
    "            \n",
    "            pred_extra=gpr.predict(x_extra)\n",
    "            pred_extra=pred_extra.reshape(-1,1)\n",
    "\n",
    "            ########### EY: Standart deviations are calculated  ################### 31/10/2023\n",
    "            pred_train_mean, pred_train_std = gpr.predict(x_train, return_std=True)     # Training set \n",
    "            pred_train_mean = pred_train_mean.reshape(-1, 1)  \n",
    "            pred_train_std = pred_train_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_mean, pred_std = gpr.predict(x_test, return_std=True)               # Test set\n",
    "            pred_mean = pred_mean.reshape(-1, 1)\n",
    "            pred_std = pred_std.reshape(-1, 1)\n",
    "            \n",
    "            pred_extra_mean, pred_extra_std = gpr.predict(x_extra, return_std=True)       # Extrapolation set \n",
    "            pred_extra_mean = pred_extra_mean.reshape(-1, 1)\n",
    "            pred_extra_std = pred_extra_std.reshape(-1, 1)\n",
    "\n",
    "            # Scale and normalize the standard deviations\n",
    "            #sc_std = StandardScaler()\n",
    "            #sc_std.fit(pred_train_std)  # Fit the scaler to the training standard deviations\n",
    "            #pred_train_std_normalized = sc_std.transform(pred_train_std)\n",
    "            #pred_std_normalized = sc_std.transform(pred_std)\n",
    "            #pred_extra_std_normalized = sc_std.transform(pred_extra_std)\n",
    "            #######################################################################  \n",
    "            \n",
    "            ################################\n",
    "            ## Train data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_train),sc_Y.inverse_transform(y_train),sc_Y.inverse_transform(pred_train)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('Train_data_predictions.xlsx', index=False, header=name)\n",
    "    \n",
    "            ################################\n",
    "            ## Test data predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_test),sc_Y.inverse_transform(y_test),sc_Y.inverse_transform(pred)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('predictions.xlsx', index=False, header=name)\n",
    "            ################################\n",
    "            ## Extrapolation predictions\n",
    "            ################################\n",
    "            data=np.concatenate((sc_X.inverse_transform(x_extra),sc_Y.inverse_transform(y_extra),sc_Y.inverse_transform(pred_extra)),axis=1)\n",
    "            dfw = pd.DataFrame(data)\n",
    "            dfw.to_excel('extrapolation.xlsx', index=False, header=name)\n",
    "            \n",
    "\n",
    "            #################################  EY: The same as above but Standart deviations are also added.\n",
    "            # Train Data Predictions (including standard deviations)\n",
    "            data_train = np.concatenate((sc_X.inverse_transform(x_train), sc_Y.inverse_transform(y_train), sc_Y.inverse_transform(pred_train), sc_Y.inverse_transform(pred_train_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_train = pd.DataFrame(data_train)\n",
    "            dfw_train.to_excel('Train_data_predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Test Data Predictions (including standard deviations)\n",
    "            data_test = np.concatenate((sc_X.inverse_transform(x_test), sc_Y.inverse_transform(y_test), sc_Y.inverse_transform(pred), sc_Y.inverse_transform(pred_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_test = pd.DataFrame(data_test)\n",
    "            dfw_test.to_excel('predictions_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "            \n",
    "            # Extrapolation Predictions (including standard deviations)\n",
    "            data_extra = np.concatenate((sc_X.inverse_transform(x_extra), sc_Y.inverse_transform(y_extra), sc_Y.inverse_transform(pred_extra), sc_Y.inverse_transform(pred_extra_std)-sc_Y.mean_), axis=1)\n",
    "            dfw_extra = pd.DataFrame(data_extra)\n",
    "            dfw_extra.to_excel('extrapolation_with_std.xlsx', index=False, header=name + ['Standard Deviation'])\n",
    "\n",
    "            ################################\n",
    "            ## Shap Part\n",
    "            ################################            \n",
    "            # Fits the explainer\n",
    "            #explainer = shap.Explainer(gpr.predict, x_test)\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer(x_test)\n",
    "            \n",
    "            #shap.summary_plot(shap_values,feature_names=name, plot_type='violin')\n",
    "\n",
    "\n",
    "            #def gpr_predict(X):\n",
    "             #   return gpr.predict(X).flatten()\n",
    "\n",
    "            # Fits the explainer\n",
    "            #explainer = shap.KernelExplainer(gpr_predict, shap.kmeans(x_train,4))\n",
    "            # Calculates the SHAP values - It takes some time\n",
    "            #shap_values = explainer.shap_values(x_test, nsamples='auto')\n",
    "            \n",
    "            #shap.summary_plot(shap_values, x_test, feature_names=name, plot_type='violin')\n",
    "           # plt.show()\n",
    "            # Create a new figure before saving to ensure the correct figure is saved\n",
    "           # plt.figure()\n",
    "\n",
    "            # Save the figure to a file (e.g., PNG)\n",
    "           # plt.savefig('shap_summary_plot.pdf', dpi=600, bbox_inches='tight')\n",
    "        \n",
    "      \n",
    "            ################################\n",
    "            ## Write rms to txt file\n",
    "            ################################\n",
    "            mse_train = np.sum(np.square(sc_Y.inverse_transform(y_train) - sc_Y.inverse_transform(pred_train))) / np.size(y_train)\n",
    "            rmse_train = np.sqrt(mse_train)\n",
    "            \n",
    "            mse = np.sum(np.square(sc_Y.inverse_transform(y_test) - sc_Y.inverse_transform(pred))) / np.size(y_test)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            ms_extra = np.sum(np.square(sc_Y.inverse_transform(y_extra) - sc_Y.inverse_transform(pred_extra))) / np.size(y_extra)\n",
    "            rms_extra = np.sqrt(ms_extra)\n",
    "            \n",
    "            wfile.write(\"rms_train=%.4f,rms_pred=%.4f, rms_extra=%.4f\\n\"%(rmse_train, rmse, rms_extra))\n",
    "            print(rmse_train, rmse,rms_extra)\n",
    "                        \n",
    "            wfile.close()\n",
    "            os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['Z', 'N', 'A', 'A^2/3', '(N-Z)/A', 'PF', 'original', 'prediction',\n",
      "       'Standard Deviation'],\n",
      "      dtype='object')\n",
      "Filtered data (Z=50):\n",
      "       Z      N      A      A^2/3   (N-Z)/A            PF  original  \\\n",
      "2411  50   42.0   92.0  20.379423 -0.086957  4.440892e-16       NaN   \n",
      "2412  50   43.0   93.0  20.526834 -0.075269  4.440892e-16       NaN   \n",
      "2413  50   44.0   94.0  20.673717 -0.063830  4.440892e-16       NaN   \n",
      "2414  50   45.0   95.0  20.820080 -0.052632  4.440892e-16       NaN   \n",
      "2415  50   46.0   96.0  20.965931 -0.041667  4.440892e-16       NaN   \n",
      "...   ..    ...    ...        ...       ...           ...       ...   \n",
      "2493  50  124.0  174.0  31.167323  0.425287  4.440892e-16       NaN   \n",
      "2494  50  125.0  175.0  31.286624  0.428571  4.440892e-16       NaN   \n",
      "2495  50  126.0  176.0  31.405698  0.431818  4.440892e-16       NaN   \n",
      "2496  50  127.0  177.0  31.524546  0.435028  4.440892e-16       NaN   \n",
      "2497  50  128.0  178.0  31.643171  0.438202  4.440892e-16       NaN   \n",
      "\n",
      "      prediction  Standard Deviation  \n",
      "2411  -18.471669            9.106989  \n",
      "2412  -23.088847            7.313508  \n",
      "2413  -27.917161            5.760731  \n",
      "2414  -32.853440            4.441263  \n",
      "2415  -37.806111            3.343335  \n",
      "...          ...                 ...  \n",
      "2493  125.679492           40.736048  \n",
      "2494  126.724507           41.996733  \n",
      "2495  127.498419           43.231214  \n",
      "2496  128.008692           44.438076  \n",
      "2497  128.263498           45.616091  \n",
      "\n",
      "[87 rows x 9 columns]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'GP_Regression/extrapolation_with_std.xlsx'  # Update this with the actual path to your file\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Check the column names to ensure they are correct\n",
    "print(\"Column names:\", df.columns)\n",
    "\n",
    "# Filter the data for Z=50\n",
    "df_Z50 = df[df['Z'] == 50]\n",
    "\n",
    "# Check the filtered data\n",
    "print(\"Filtered data (Z=50):\")\n",
    "print(df_Z50)\n",
    "\n",
    "# Convert columns to numpy arrays before plotting\n",
    "N_values = df_Z50['N'].values\n",
    "prediction_values = df_Z50['prediction'].values\n",
    "\n",
    "# Plot the prediction as a function of neutron number\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(N_values, prediction_values, marker='o', linestyle='-', color='b', label='Prediction')\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Prediction for Z=50 Isotopic Chain as a Function of Neutron Number')\n",
    "plt.xlabel('Neutron Number (N)')\n",
    "plt.ylabel('Prediction')\n",
    "plt.legend()\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data(file_path, label, color):\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Filter the data for Z=50\n",
    "    df_Z50 = df[df['Z'] == 40]\n",
    "    \n",
    "    # Convert columns to numpy arrays before plotting\n",
    "    N_values = df_Z50['N'].values\n",
    "    prediction_values = df_Z50['prediction'].values\n",
    "    \n",
    "    # Plot the prediction as a function of neutron number\n",
    "#    plt.plot(N_values, prediction_values, marker='o', linestyle='-', color=color, label=label)\n",
    "     # Plot the prediction as a function of neutron number with black borders around the dots\n",
    "    plt.plot(N_values, prediction_values, marker='o', linestyle='-', color=color, label=label, markerfacecolor=color, markeredgewidth=1, markeredgecolor='black')\n",
    "\n",
    "\n",
    "# File paths for each dataset\n",
    "file_paths = [\n",
    "    'GP_Regression/extrapolation_with_std.xlsx',  \n",
    "    'GP_Regression/WS4.xlsx',           \n",
    "    'GP_Regression/FRDM2012.xlsx'        \n",
    "]\n",
    "\n",
    "# Labels and colors for each dataset\n",
    "labels = ['GPR', 'WS4', 'FRDM2012']\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'orange', 'purple', 'lime', 'pink', 'olive', 'brown', 'navy', 'teal', 'maroon']\n",
    "\n",
    "# Plot each dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "for file_path, label, color in zip(file_paths, labels, colors):\n",
    "    plot_data(file_path, label, color)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Mass excess predictions for Z=50 Isotopic Chain as a Function of Neutron Number', fontsize=12)\n",
    "plt.xlabel('Neutron Number (N)', fontsize=16)\n",
    "plt.ylabel('Mass excess [MeV]', fontsize=16)\n",
    "plt.legend()\n",
    "\n",
    "# Remove background grid lines\n",
    "plt.grid(which='both', color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 'std' column not found in GP_Regression/extrapolation_with_std.xlsx. Using synthetic confidence intervals.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_with_confidence_interval(file_path, label, color, plot_confidence=False):\n",
    "    # Load the Excel file\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Filter the data for Z=50\n",
    "    df_Z50 = df[df['Z'] == 40]\n",
    "\n",
    "    # Convert columns to numpy arrays before plotting\n",
    "    N_values = df_Z50['N'].values\n",
    "    prediction_values = df_Z50['prediction'].values\n",
    "\n",
    "    if plot_confidence:\n",
    "        # Check if the 'std' column exists\n",
    "        if 'std' in df_Z50.columns:\n",
    "            std_values = df_Z50['std'].values\n",
    "        else:\n",
    "            print(f\"Warning: 'std' column not found in {file_path}. Using synthetic confidence intervals.\")\n",
    "            std_values = 5  # You can adjust this value based on your needs\n",
    "\n",
    "        lower_bound = prediction_values - 1.96 * std_values\n",
    "        upper_bound = prediction_values + 1.96 * std_values\n",
    "        plt.fill_between(N_values, lower_bound, upper_bound, color=color, alpha=0.3)\n",
    "\n",
    "    # Plot the prediction as a function of neutron number\n",
    "    plt.plot(N_values, prediction_values, marker='o', linestyle='-', color=color, label=label)\n",
    "\n",
    "# File paths for each dataset\n",
    "file_paths = [\n",
    "    'GP_Regression/extrapolation_with_std.xlsx',  # GPR with confidence intervals\n",
    "    'GP_Regression/WS4.xlsx',\n",
    "    'GP_Regression/FRDM2012.xlsx'\n",
    "]\n",
    "\n",
    "# Labels and colors for each dataset\n",
    "labels = ['GPR', 'WS4', 'FRDM2012']\n",
    "colors = ['b', 'g', 'r']\n",
    "\n",
    "# Plot each dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "for file_path, label, color in zip(file_paths, labels, colors):\n",
    "    if label == 'GPR':\n",
    "        plot_data_with_confidence_interval(file_path, label, color, plot_confidence=True)\n",
    "    else:\n",
    "        plot_data_with_confidence_interval(file_path, label, color, plot_confidence=False)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('Mass excess predictions for Z=50 Isotopic Chain as a Function of Neutron Number')\n",
    "plt.xlabel('Neutron Number (N)', fontsize=16)\n",
    "plt.ylabel('Mass excess [MeV]', fontsize=16)\n",
    "plt.legend()\n",
    "\n",
    "# Remove background grid lines\n",
    "plt.grid(which='both', color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
